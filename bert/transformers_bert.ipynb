{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 667
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 21927,
     "status": "ok",
     "timestamp": 1575248625655,
     "user": {
      "displayName": "郑二城",
      "photoUrl": "",
      "userId": "06789319190591080352"
     },
     "user_tz": -480
    },
    "id": "IZ0rjD0mvNHo",
    "outputId": "dfdb26c8-c7bc-4132-d078-c0ddbc847fbb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ec/e7/0a1babead1b79afabb654fbec0a052e0d833ba4205a6dfd98b1aeda9c82e/transformers-2.2.0-py3-none-any.whl (360kB)\n",
      "\r",
      "\u001b[K     |█                               | 10kB 18.3MB/s eta 0:00:01\r",
      "\u001b[K     |█▉                              | 20kB 1.7MB/s eta 0:00:01\r",
      "\u001b[K     |██▊                             | 30kB 2.5MB/s eta 0:00:01\r",
      "\u001b[K     |███▋                            | 40kB 1.6MB/s eta 0:00:01\r",
      "\u001b[K     |████▌                           | 51kB 2.0MB/s eta 0:00:01\r",
      "\u001b[K     |█████▌                          | 61kB 2.4MB/s eta 0:00:01\r",
      "\u001b[K     |██████▍                         | 71kB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |███████▎                        | 81kB 3.2MB/s eta 0:00:01\r",
      "\u001b[K     |████████▏                       | 92kB 3.5MB/s eta 0:00:01\r",
      "\u001b[K     |█████████                       | 102kB 2.7MB/s eta 0:00:01\r",
      "\u001b[K     |██████████                      | 112kB 2.7MB/s eta 0:00:01\r",
      "\u001b[K     |███████████                     | 122kB 2.7MB/s eta 0:00:01\r",
      "\u001b[K     |███████████▉                    | 133kB 2.7MB/s eta 0:00:01\r",
      "\u001b[K     |████████████▊                   | 143kB 2.7MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████▋                  | 153kB 2.7MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████▌                 | 163kB 2.7MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████▌                | 174kB 2.7MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████▍               | 184kB 2.7MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████▎              | 194kB 2.7MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████▏             | 204kB 2.7MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████             | 215kB 2.7MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████            | 225kB 2.7MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████           | 235kB 2.7MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████▉          | 245kB 2.7MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████▊         | 256kB 2.7MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████▋        | 266kB 2.7MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████▌       | 276kB 2.7MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████▍      | 286kB 2.7MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████▍     | 296kB 2.7MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████▎    | 307kB 2.7MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████▏   | 317kB 2.7MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████████   | 327kB 2.7MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████████  | 337kB 2.7MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████████ | 348kB 2.7MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████████▉| 358kB 2.7MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████████| 368kB 2.7MB/s \n",
      "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.21.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.17.4)\n",
      "Collecting regex\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e3/8e/cbf2295643d7265e7883326fb4654e643bfc93b3a8a8274d8010a39d8804/regex-2019.11.1-cp36-cp36m-manylinux1_x86_64.whl (643kB)\n",
      "\r",
      "\u001b[K     |▌                               | 10kB 19.5MB/s eta 0:00:01\r",
      "\u001b[K     |█                               | 20kB 26.2MB/s eta 0:00:01\r",
      "\u001b[K     |█▌                              | 30kB 33.2MB/s eta 0:00:01\r",
      "\u001b[K     |██                              | 40kB 38.1MB/s eta 0:00:01\r",
      "\u001b[K     |██▌                             | 51kB 40.5MB/s eta 0:00:01\r",
      "\u001b[K     |███                             | 61kB 43.2MB/s eta 0:00:01\r",
      "\u001b[K     |███▋                            | 71kB 44.5MB/s eta 0:00:01\r",
      "\u001b[K     |████                            | 81kB 45.1MB/s eta 0:00:01\r",
      "\u001b[K     |████▋                           | 92kB 46.7MB/s eta 0:00:01\r",
      "\u001b[K     |█████                           | 102kB 48.6MB/s eta 0:00:01\r",
      "\u001b[K     |█████▋                          | 112kB 48.6MB/s eta 0:00:01\r",
      "\u001b[K     |██████                          | 122kB 48.6MB/s eta 0:00:01\r",
      "\u001b[K     |██████▋                         | 133kB 48.6MB/s eta 0:00:01\r",
      "\u001b[K     |███████▏                        | 143kB 48.6MB/s eta 0:00:01\r",
      "\u001b[K     |███████▋                        | 153kB 48.6MB/s eta 0:00:01\r",
      "\u001b[K     |████████▏                       | 163kB 48.6MB/s eta 0:00:01\r",
      "\u001b[K     |████████▋                       | 174kB 48.6MB/s eta 0:00:01\r",
      "\u001b[K     |█████████▏                      | 184kB 48.6MB/s eta 0:00:01\r",
      "\u001b[K     |█████████▊                      | 194kB 48.6MB/s eta 0:00:01\r",
      "\u001b[K     |██████████▏                     | 204kB 48.6MB/s eta 0:00:01\r",
      "\u001b[K     |██████████▊                     | 215kB 48.6MB/s eta 0:00:01\r",
      "\u001b[K     |███████████▏                    | 225kB 48.6MB/s eta 0:00:01\r",
      "\u001b[K     |███████████▊                    | 235kB 48.6MB/s eta 0:00:01\r",
      "\u001b[K     |████████████▏                   | 245kB 48.6MB/s eta 0:00:01\r",
      "\u001b[K     |████████████▊                   | 256kB 48.6MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████▎                  | 266kB 48.6MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████▊                  | 276kB 48.6MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████▎                 | 286kB 48.6MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████▊                 | 296kB 48.6MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████▎                | 307kB 48.6MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████▉                | 317kB 48.6MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████▎               | 327kB 48.6MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████▉               | 337kB 48.6MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████▎              | 348kB 48.6MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████▉              | 358kB 48.6MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████▎             | 368kB 48.6MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████▉             | 378kB 48.6MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████▍            | 389kB 48.6MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████▉            | 399kB 48.6MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████▍           | 409kB 48.6MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████▉           | 419kB 48.6MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████▍          | 430kB 48.6MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████          | 440kB 48.6MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████▍         | 450kB 48.6MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████         | 460kB 48.6MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████▍        | 471kB 48.6MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████        | 481kB 48.6MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████▍       | 491kB 48.6MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████       | 501kB 48.6MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████▌      | 512kB 48.6MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████      | 522kB 48.6MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████▌     | 532kB 48.6MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████     | 542kB 48.6MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████▌    | 552kB 48.6MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████    | 563kB 48.6MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████▌   | 573kB 48.6MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████████   | 583kB 48.6MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████████▌  | 593kB 48.6MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████████  | 604kB 48.6MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████████▌ | 614kB 48.6MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████████ | 624kB 48.6MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████████▋| 634kB 48.6MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████████| 645kB 48.6MB/s \n",
      "\u001b[?25hCollecting sentencepiece\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/14/3d/efb655a670b98f62ec32d66954e1109f403db4d937c50d779a75b9763a29/sentencepiece-0.1.83-cp36-cp36m-manylinux1_x86_64.whl (1.0MB)\n",
      "\u001b[K     |████████████████████████████████| 1.0MB 42kB/s \n",
      "\u001b[?25hCollecting sacremoses\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1f/8e/ed5364a06a9ba720fddd9820155cc57300d28f5f43a6fd7b7e817177e642/sacremoses-0.0.35.tar.gz (859kB)\n",
      "\u001b[K     |████████████████████████████████| 860kB 40.8MB/s \n",
      "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from transformers) (4.28.1)\n",
      "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from transformers) (1.10.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2019.9.11)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.8)\n",
      "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.12.0)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.0)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.14.0)\n",
      "Requirement already satisfied: s3transfer<0.3.0,>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.2.1)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.9.4)\n",
      "Requirement already satisfied: botocore<1.14.0,>=1.13.18 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (1.13.18)\n",
      "Requirement already satisfied: python-dateutil<2.8.1,>=2.1; python_version >= \"2.7\" in /usr/local/lib/python3.6/dist-packages (from botocore<1.14.0,>=1.13.18->boto3->transformers) (2.6.1)\n",
      "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.14.0,>=1.13.18->boto3->transformers) (0.15.2)\n",
      "Building wheels for collected packages: sacremoses\n",
      "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for sacremoses: filename=sacremoses-0.0.35-cp36-none-any.whl size=883999 sha256=da5ee58229d35b15605638e54a603a0cb8c6d5f73fd4a1b706af8a93eadadf2e\n",
      "  Stored in directory: /root/.cache/pip/wheels/63/2a/db/63e2909042c634ef551d0d9ac825b2b0b32dede4a6d87ddc94\n",
      "Successfully built sacremoses\n",
      "Installing collected packages: regex, sentencepiece, sacremoses, transformers\n",
      "Successfully installed regex-2019.11.1 sacremoses-0.0.35 sentencepiece-0.1.83 transformers-2.2.0\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7nITXqUoqxp4"
   },
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EmmoVpH4tlo9"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "\n",
    "class SentimentDataset(Dataset):\n",
    "\tdef __init__(self, path_to_file):\n",
    "\t\tself.dataset = pd.read_csv(path_to_file, sep=\"\\t\", names=[\"text\", \"label\"])\n",
    "\tdef __len__(self):\n",
    "\t\treturn len(self.dataset)\n",
    "\tdef __getitem__(self, idx):\n",
    "\t\ttext = self.dataset.loc[idx, \"text\"]\n",
    "\t\tlabel = self.dataset.loc[idx, \"label\"]\n",
    "\t\tsample = {\"text\": text, \"label\": label}\n",
    "\t\treturn sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 81
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3144,
     "status": "ok",
     "timestamp": 1575248687685,
     "user": {
      "displayName": "郑二城",
      "photoUrl": "",
      "userId": "06789319190591080352"
     },
     "user_tz": -480
    },
    "id": "7NW9E58avD6K",
    "outputId": "b3c78814-8e67-4d3e-ad97-656d708cba03"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p style=\"color: red;\">\n",
       "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
       "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
       "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
       "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from transformers import BertTokenizer\n",
    "from transformers import BertForSequenceClassification, BertModel\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import AdamW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PZblz3sevYil"
   },
   "outputs": [],
   "source": [
    "# 超参数\n",
    "hidden_dropout_prob = 0.5\n",
    "num_labels = 2\n",
    "learning_rate = 1e-5\n",
    "weight_decay = 1e-2\n",
    "epochs = 2\n",
    "max_len = 100\n",
    "batch_size = 16\n",
    "class_num = 2\n",
    "\n",
    "base_path = \"/content/drive/My Drive/Colab Notebooks/\"\n",
    "vocab_file = base_path + \"PyTorch_Pretrained_Model/chinese_wwm_pytorch/vocab.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2558,
     "status": "ok",
     "timestamp": 1575248689587,
     "user": {
      "displayName": "郑二城",
      "photoUrl": "",
      "userId": "06789319190591080352"
     },
     "user_tz": -480
    },
    "id": "r5Nm0G0HwMtF",
    "outputId": "649bd905-5cb5-4ae8-c835-ea81e615c2c7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Tesla K80'"
      ]
     },
     "execution_count": 8,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.get_device_name(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4X4oXRVDwE__"
   },
   "outputs": [],
   "source": [
    "# 使用GPU\n",
    "# 然后通过model.to(device)的方式使用\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "W3XdNer6MQyn"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Vdjl8dzSwUqC"
   },
   "outputs": [],
   "source": [
    "data_path = base_path + \"/data/sentiment/\"\n",
    "# 加载数据集\n",
    "sentiment_train_set = SentimentDataset(data_path + \"sentiment.train.data\")\n",
    "sentiment_train_loader = DataLoader(sentiment_train_set, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "\n",
    "sentiment_valid_set = SentimentDataset(data_path + \"sentiment.train.data\")\n",
    "sentiment_valid_loader = DataLoader(sentiment_valid_set, batch_size=batch_size, shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yZ6GFtFOwh_W"
   },
   "outputs": [],
   "source": [
    "# 加载模型\n",
    "# transformers也可以从网络下载预训练模型\n",
    "# 如果是用本地路径确认3个文件的名称为config.json，pytorch_model.bin和vocab.txt\n",
    "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hc1_wjmOxHQZ"
   },
   "outputs": [],
   "source": [
    "# 定义优化器和损失函数\n",
    "# Prepare optimizer and schedule (linear warmup and decay)\n",
    "no_decay = ['bias', 'LayerNorm.weight']\n",
    "optimizer_grouped_parameters = [\n",
    "        {'params': [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)], 'weight_decay': weight_decay},\n",
    "        {'params': [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
    "]\n",
    "#optimizer = AdamW(model.parameters(), lr=learning_rate)\n",
    "optimizer = AdamW(optimizer_grouped_parameters, lr=learning_rate)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "tokenizer = BertTokenizer(vocab_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NzULEB8MyzR7"
   },
   "outputs": [],
   "source": [
    "def convert_text_to_ids(tokenizer, text, max_len=100):\n",
    "\tif isinstance(text, str):\n",
    "\t\ttokenized_text = tokenizer.encode_plus(text, max_length=max_len, add_special_tokens=True)\n",
    "\t\tinput_ids = tokenized_text[\"input_ids\"]\n",
    "\t\ttoken_type_ids = tokenized_text[\"token_type_ids\"]\n",
    "\telif isinstance(text, list):\n",
    "\t\tinput_ids = []\n",
    "\t\ttoken_type_ids = []\n",
    "\t\tfor t in text:\n",
    "\t\t\ttokenized_text = tokenizer.encode_plus(t, max_length=max_len, add_special_tokens=True)\n",
    "\t\t\tinput_ids.append(tokenized_text[\"input_ids\"])\n",
    "\t\t\ttoken_type_ids.append(tokenized_text[\"token_type_ids\"])\n",
    "\telse:\n",
    "\t\tprint(\"Unexpected input\")\n",
    "\treturn input_ids, token_type_ids\n",
    "\n",
    "\n",
    "def seq_padding(tokenizer, X):\n",
    "\tpad_id = tokenizer.convert_tokens_to_ids(\"[PAD]\")\n",
    "\tif len(X) <= 1:\n",
    "\t\treturn X\n",
    "\tL = [len(x) for x in X]\n",
    "\tML = max(L)\n",
    "\tX = torch.Tensor([x + [pad_id] * (ML - len(x)) if len(x) < ML else x for x in X])\n",
    "\t#X.requires_grad = True\n",
    "\treturn X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NIkFb-Hey1ov"
   },
   "outputs": [],
   "source": [
    "def train(model, iterator, optimizer, criterion, device, clip):\n",
    "\tmodel.to(device)\n",
    "\tmodel.train()\n",
    "\tepoch_loss = 0\n",
    "\tepoch_acc = 0\n",
    "\tfor i, batch in enumerate(iterator):\n",
    "\t\tlabel = batch[\"label\"]\n",
    "\t\ttext = batch[\"text\"]\n",
    "\t\tinput_ids, token_type_ids = convert_text_to_ids(tokenizer, text)\n",
    "\t\tinput_ids = seq_padding(tokenizer, input_ids)\n",
    "\t\ttoken_type_ids = seq_padding(tokenizer, token_type_ids)\n",
    "\t\t# 标签形状为 (batch_size, 1) \n",
    "\t\tlabel = label.unsqueeze(1)\n",
    "\t\t# 需要 LongTensor\n",
    "\t\tinput_ids, token_type_ids, label = input_ids.long(), token_type_ids.long(), label.long()\n",
    "\t\t# 梯度清零\n",
    "\t\toptimizer.zero_grad()\n",
    "\t\t# 迁移到GPU\n",
    "\t\tinput_ids, token_type_ids, label = input_ids.to(device), token_type_ids.to(device), label.to(device)\n",
    "\t\t# (loss), logits, (hidden_states), (attentions)\n",
    "\t\t# (hidden_states), (attentions) 不一定存在\n",
    "\t\toutput = model(input_ids=input_ids, token_type_ids=token_type_ids, labels=label)\n",
    "\t\ty_pred_prob = output[1]\n",
    "\t\ty_pred_label = y_pred_prob.argmax(dim=1)\n",
    "\t\t# 计算loss\n",
    "\t\t#loss = criterion(y_pred_prob.view(-1, 2), label.view(-1))\n",
    "\t\tloss = output[0]\n",
    "\t\t# 计算acc\n",
    "\t\tacc = ((y_pred_label == label.view(-1)).sum()).item()\n",
    "\t\t# 梯度裁剪\n",
    "\t\t#torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "\t\t# 反向传播\n",
    "\t\tloss.backward()\n",
    "\t\toptimizer.step()\n",
    "\t\t# epoch 中的 loss 和 acc 累加\n",
    "\t\tepoch_loss += loss.item()\n",
    "\t\tepoch_acc += acc\n",
    "\t\tif i % 100 == 0:\n",
    "\t\t\tprint(\"current loss:\", epoch_loss / (i+1), \"\\t\", \"current acc:\", epoch_acc / ((i+1)*len(label)))\n",
    "\treturn epoch_loss / len(iterator), epoch_acc / len(iterator.dataset.dataset)\n",
    "\n",
    "def evaluate(model, iterator, criterion, device):\n",
    "\tmodel.to(device)\n",
    "\tmodel.eval()\n",
    "\tepoch_loss = 0\n",
    "\tepoch_acc = 0\n",
    "\twith torch.no_grad():\n",
    "\t\tfor _, batch in enumerate(iterator):\n",
    "\t\t\tlabel = batch[\"label\"]\n",
    "\t\t\ttext = batch[\"text\"]\n",
    "\t\t\tinput_ids, token_type_ids = convert_text_to_ids(tokenizer, text)\n",
    "\t\t\tinput_ids = seq_padding(tokenizer, input_ids)\n",
    "\t\t\ttoken_type_ids = seq_padding(tokenizer, token_type_ids)\n",
    "\t\t\t# 标签形状为 (batch_size, 1) \n",
    "\t\t\tlabel = label.unsqueeze(1)\n",
    "\t\t\t# 需要 LongTensor\n",
    "\t\t\tinput_ids, token_type_ids, label = input_ids.long(), token_type_ids.long(), label.long()\n",
    "\t\t\t# 迁移到GPU\n",
    "\t\t\tinput_ids, token_type_ids, label = input_ids.to(device), token_type_ids.to(device), label.to(device)\n",
    "\t\t\toutput = model(input_ids=input_ids, token_type_ids=token_type_ids, labels=label)\n",
    "\t\t\ty_pred_label = output[1].argmax(dim=1)\n",
    "\t\t\tloss = output[0]\n",
    "\t\t\tacc = ((y_pred_label == label.view(-1)).sum()).item()\n",
    "\t\t\tepoch_loss += loss.item()\n",
    "\t\t\tepoch_acc += acc\n",
    "\treturn epoch_loss / len(iterator), epoch_acc / len(iterator.dataset.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 953
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 608,
     "status": "ok",
     "timestamp": 1574864249659,
     "user": {
      "displayName": "郑二城",
      "photoUrl": "",
      "userId": "06789319190591080352"
     },
     "user_tz": -480
    },
    "id": "qaTC2OtVy4Gx",
    "outputId": "a43fd02a-e457-4a97-a972-974105a9ba15"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on GPU\n",
      "current loss: 0.6535788178443909 \t current acc: 0.6875\n",
      "current loss: 0.6699029826650432 \t current acc: 0.5857843137254902\n",
      "current loss: 0.6760076998484017 \t current acc: 0.5792079207920792\n",
      "current loss: 0.6762414921987925 \t current acc: 0.5823675496688742\n",
      "current loss: 0.669018224697208 \t current acc: 0.5948383084577115\n",
      "current loss: 0.6682184906119845 \t current acc: 0.5971115537848606\n",
      "current loss: 0.6643820257479962 \t current acc: 0.604235880398671\n",
      "current loss: 0.6600956170477419 \t current acc: 0.6107549857549858\n",
      "current loss: 0.6605680557409129 \t current acc: 0.6126870324189526\n",
      "current loss: 0.6558593532066388 \t current acc: 0.614329268292683\n",
      "current loss: 0.6493636944336806 \t current acc: 0.6227544910179641\n",
      "current loss: 0.6429205579571629 \t current acc: 0.6306715063520871\n",
      "current loss: 0.6372712821809702 \t current acc: 0.6363352745424293\n",
      "current loss: 0.6260670349803023 \t current acc: 0.6469854070660522\n",
      "current loss: 0.6159548913148603 \t current acc: 0.6557596291012838\n",
      "current loss: 0.6069771790512393 \t current acc: 0.6636151797603196\n",
      "current loss: 0.5973021889038003 \t current acc: 0.6716604244694132\n",
      "current loss: 0.5857147136144997 \t current acc: 0.6804494712103408\n",
      "current loss: 0.5763518650014445 \t current acc: 0.6878468368479467\n",
      "current loss: 0.5677579365177109 \t current acc: 0.6948606729758149\n",
      "current loss: 0.5597112627251523 \t current acc: 0.7008616383616384\n",
      "current loss: 0.5528396871561214 \t current acc: 0.7063510941960038\n",
      "train loss:  0.5522188970576777 \t train acc: 0.7062559354226021\n",
      "validating on GPU\n",
      "valid loss:  0.3108285240128509 \t valid acc: 0.8764838556505223\n",
      "training on GPU\n",
      "current loss: 0.33956781029701233 \t current acc: 0.8125\n",
      "current loss: 0.3215515059875507 \t current acc: 0.8700980392156863\n",
      "current loss: 0.3508986198518536 \t current acc: 0.8539603960396039\n",
      "current loss: 0.33568099681411356 \t current acc: 0.8600993377483444\n",
      "current loss: 0.3326827608864402 \t current acc: 0.8619402985074627\n",
      "current loss: 0.33328965165285 \t current acc: 0.8647908366533864\n",
      "current loss: 0.3318574161599839 \t current acc: 0.867109634551495\n",
      "current loss: 0.32736359964366313 \t current acc: 0.8696581196581197\n",
      "current loss: 0.32672746549186266 \t current acc: 0.8676745635910225\n",
      "current loss: 0.3272633646468233 \t current acc: 0.8673780487804879\n",
      "current loss: 0.32699079178794177 \t current acc: 0.8677644710578842\n",
      "current loss: 0.32559895889323115 \t current acc: 0.8674001814882033\n",
      "current loss: 0.3234553332572273 \t current acc: 0.8684484193011647\n",
      "current loss: 0.3216427795405853 \t current acc: 0.8683755760368663\n",
      "current loss: 0.3209300644313133 \t current acc: 0.8682239657631954\n",
      "current loss: 0.32015298255849456 \t current acc: 0.8680093209054593\n",
      "current loss: 0.31717104622431463 \t current acc: 0.8688358302122348\n",
      "current loss: 0.31580673647140506 \t current acc: 0.8693448883666275\n",
      "current loss: 0.31463343179996617 \t current acc: 0.8697280799112098\n",
      "current loss: 0.3123242025715069 \t current acc: 0.8705310199789695\n",
      "current loss: 0.3096752797479515 \t current acc: 0.8719405594405595\n",
      "current loss: 0.3083460011531011 \t current acc: 0.8724429115128449\n",
      "train loss:  0.3080443272761583 \t train acc: 0.8720916429249762\n",
      "validating on GPU\n",
      "valid loss:  0.17984334123652546 \t valid acc: 0.9366690408357075\n"
     ]
    }
   ],
   "source": [
    "for i in range(epochs):\n",
    "\ttrain_loss, train_acc = train(model, sentiment_train_loader, optimizer, criterion, device, 1)\n",
    "\tprint(\"train loss: \", train_loss, \"\\t\", \"train acc:\", train_acc)\n",
    "\tvalid_loss, valid_acc = evaluate(model, sentiment_valid_loader, criterion, device)\n",
    "\tprint(\"valid loss: \", valid_loss, \"\\t\", \"valid acc:\", valid_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DxkioH3ty6hE"
   },
   "outputs": [],
   "source": [
    "from transformers import BertConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EKb4yo_BSdRB"
   },
   "outputs": [],
   "source": [
    "config = BertConfig.from_pretrained(\"bert-base-uncased\", num_labels=num_labels, config = BertConfig.from_pretrained(\"bert-base-uncased\", num_labels=num_labels, hidden_dropout_prob=hidden_dropout_prob))\n",
    "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 593
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 560581,
     "status": "ok",
     "timestamp": 1574941807907,
     "user": {
      "displayName": "郑二城",
      "photoUrl": "",
      "userId": "06789319190591080352"
     },
     "user_tz": -480
    },
    "id": "ypuOodSyTz_o",
    "outputId": "a87f1ae5-e9ed-462d-cae9-d825eca8b71a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current loss: 0.6253945231437683 \t current acc: 0.75\n",
      "current loss: 0.6724979877471924 \t current acc: 0.594059405940594\n",
      "current loss: 0.6675496136964257 \t current acc: 0.595771144278607\n",
      "current loss: 0.6500755327682558 \t current acc: 0.6218853820598007\n",
      "current loss: 0.6304198570753868 \t current acc: 0.6447942643391521\n",
      "current loss: 0.6088782434989354 \t current acc: 0.6645459081836327\n",
      "current loss: 0.5883931425615476 \t current acc: 0.6828202995008319\n",
      "current loss: 0.5731407172244558 \t current acc: 0.6957917261055635\n",
      "current loss: 0.5600425008865778 \t current acc: 0.7063046192259675\n",
      "current loss: 0.5460098291210805 \t current acc: 0.7180216426193119\n",
      "current loss: 0.5335281072975276 \t current acc: 0.728021978021978\n",
      "\n",
      "\n",
      "train loss:  0.5258307942637691 \t train acc: 0.7331433998100665\n",
      "valid loss:  0.32960593094739704 \t valid acc: 0.8585588793922128\n",
      "\n",
      "current loss: 0.6428508758544922 \t current acc: 0.625\n",
      "current loss: 0.36294595543110725 \t current acc: 0.8409653465346535\n",
      "current loss: 0.3547838136034818 \t current acc: 0.849502487562189\n",
      "current loss: 0.34617458516577154 \t current acc: 0.8556893687707641\n",
      "current loss: 0.34331724987808904 \t current acc: 0.8576995012468828\n",
      "current loss: 0.3397262508492032 \t current acc: 0.8592814371257484\n",
      "current loss: 0.337272990501165 \t current acc: 0.8587770382695508\n",
      "current loss: 0.33586538658502607 \t current acc: 0.8578815977175464\n",
      "current loss: 0.3344943511873 \t current acc: 0.8588483146067416\n",
      "current loss: 0.3298531147205869 \t current acc: 0.8605715871254163\n",
      "current loss: 0.3261045743967151 \t current acc: 0.8626373626373627\n",
      "\n",
      "\n",
      "train loss:  0.32484621564872695 \t train acc: 0.8631885090218424\n",
      "valid loss:  0.19804399505130246 \t valid acc: 0.929190408357075\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(epochs):\n",
    "\ttrain_loss, train_acc = train(model, sentiment_train_loader, optimizer, criterion, device, 1)\n",
    "\tvalid_loss, valid_acc = evaluate(model, sentiment_valid_loader, criterion, device)\n",
    "\tprint(\"\\n\")\n",
    "\tprint(\"train loss: \", train_loss, \"\\t\", \"train acc:\", train_acc)\n",
    "\tprint(\"valid loss: \", valid_loss, \"\\t\", \"valid acc:\", valid_acc, end=\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hjIzK655_4Gm"
   },
   "outputs": [],
   "source": [
    "# 保存\n",
    "model.save_pretrained(\"./\")\n",
    "tokenizer.save_pretrained(\"./\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "PyTorch.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
